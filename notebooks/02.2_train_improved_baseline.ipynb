{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Improved Baseline Model (Memory-Efficient for 8GB GPU)\n",
    "\n",
    "This notebook trains the **improved baseline model** with optimizations for limited GPU memory.\n",
    "\n",
    "## Improved Baseline Features:\n",
    "- **Deeper CNN encoder** (4 conv layers vs 3)\n",
    "- **Bidirectional LSTM** for temporal modeling\n",
    "- **Audio context concatenation** with word embeddings\n",
    "- **Dropout** for regularization\n",
    "- **Average pooling** instead of max pooling (preserves temporal info)\n",
    "\n",
    "## Memory Optimizations for 8GB GPU:\n",
    "- Smaller batch size (16 vs 32)\n",
    "- Reduced embedding dimension (256)\n",
    "- Reduced hidden dimension (512)\n",
    "- 2 LSTM layers\n",
    "\n",
    "**Estimated time**: 3-5 hours (30 epochs on GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'  # Fix threading issue\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'  # Better memory allocation\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "project_root = Path('..').absolute()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import json\n",
    "from src.models import create_model\n",
    "from src.dataset import create_dataloaders\n",
    "from src.trainer import ModelTrainer\n",
    "from src.utils import load_vocab, set_seed, get_device, count_parameters, make_json_serializable\n",
    "\n",
    "print(\"‚úì Imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set Random Seed and Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "device = get_device()\n",
    "\n",
    "# Check GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    free_memory = torch.cuda.mem_get_info()[0] / 1024**3\n",
    "    print(f\"\\nGPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Total GPU memory: {total_memory:.2f} GB\")\n",
    "    print(f\"Free GPU memory: {free_memory:.2f} GB\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No GPU available, using CPU (will be slower)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading vocabulary...\")\n",
    "vocab = load_vocab('../vocab.json')\n",
    "print(f\"\\n‚úì Vocabulary size: {len(vocab)}\")\n",
    "print(f\"  <pad>: {vocab['<pad>']}\")\n",
    "print(f\"  <sos>: {vocab['<sos>']}\")\n",
    "print(f\"  <eos>: {vocab['<eos>']}\")\n",
    "print(f\"  <unk>: {vocab['<unk>']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Dataloaders with Optimized Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating dataloaders...\")\n",
    "print(\"Using batch_size=16 (optimized for 8GB GPU)\\n\")\n",
    "\n",
    "train_loader, val_loader, eval_dataset = create_dataloaders(\n",
    "    train_captions='../data/train_captions.json',\n",
    "    val_captions='../data/val_captions.json',\n",
    "    eval_captions='../data/eval_captions.json',\n",
    "    train_features_dir='../features/mel/',\n",
    "    val_features_dir='../features/mel/',\n",
    "    eval_features_dir='../features/mel_eval/',\n",
    "    vocab=vocab,\n",
    "    batch_size=16,      # Optimized for improved baseline\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Dataloaders created:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Eval samples: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Improved Baseline Model\n",
    "\n",
    "The improved baseline adds:\n",
    "- Deeper CNN (4 layers)\n",
    "- Bidirectional LSTM for encoding\n",
    "- Audio context concatenated with embeddings\n",
    "- Dropout for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating IMPROVED BASELINE model...\\n\")\n",
    "print(\"Model configuration:\")\n",
    "print(\"  - Embedding dimension: 256\")\n",
    "print(\"  - Hidden dimension: 512\")\n",
    "print(\"  - LSTM layers: 2\")\n",
    "print(\"  - CNN layers: 4 (deeper than baseline)\")\n",
    "print(\"  - Bidirectional encoder LSTM\")\n",
    "print(\"  - Audio context concatenation\")\n",
    "print(\"  - Dropout: 0.3\\n\")\n",
    "\n",
    "model = create_model(\n",
    "    'improved_baseline', \n",
    "    vocab_size=len(vocab),\n",
    "    embed_dim=256,\n",
    "    hidden_dim=512,\n",
    "    num_layers=2\n",
    ")\n",
    "\n",
    "print(\"\\nModel architecture:\")\n",
    "print(model)\n",
    "\n",
    "print(\"\\nParameter count:\")\n",
    "total_params, trainable_params = count_parameters(model)\n",
    "\n",
    "# Estimate memory\n",
    "model_memory = total_params * 4 / (1024**3)  # 4 bytes per param (float32)\n",
    "print(f\"\\nEstimated model memory: {model_memory:.2f} GB\")\n",
    "\n",
    "# Move to GPU and check actual usage\n",
    "print(\"\\nMoving model to GPU...\")\n",
    "model = model.to(device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "    reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "    free = torch.cuda.mem_get_info()[0] / 1024**3\n",
    "    \n",
    "    print(f\"\\nGPU Memory Status After Loading Model:\")\n",
    "    print(f\"  Allocated: {allocated:.2f} GB\")\n",
    "    print(f\"  Reserved: {reserved:.2f} GB\")\n",
    "    print(f\"  Free: {free:.2f} GB\")\n",
    "    \n",
    "    if free > 3:\n",
    "        print(f\"\\n‚úì Model fits comfortably in GPU memory! ({free:.2f} GB free)\")\n",
    "    elif free > 1:\n",
    "        print(f\"\\n‚úì Model fits in GPU memory! ({free:.2f} GB free)\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è Low memory warning: only {free:.2f} GB free\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing trainer...\")\n",
    "\n",
    "trainer = ModelTrainer(\n",
    "    model=model,\n",
    "    vocab=vocab,\n",
    "    device=device,\n",
    "    model_name='improved_baseline'\n",
    ")\n",
    "\n",
    "print(\"‚úì Trainer ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train Model\n",
    "\n",
    "**This will take 3-5 hours on GPU**\n",
    "\n",
    "Progress will be shown with:\n",
    "- Training loss per batch (progress bar)\n",
    "- Validation loss per epoch\n",
    "- Sample generations every 5 epochs\n",
    "- Learning rate changes\n",
    "- Early stopping if no improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\\n\")\n",
    "print(\"=\"*80)\n",
    "print(\"IMPROVED BASELINE MODEL TRAINING\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nTraining improved baseline with:\")\n",
    "print(\"  - Deeper CNN encoder\")\n",
    "print(\"  - Bidirectional LSTM\")\n",
    "print(\"  - Audio context concatenation\")\n",
    "print(\"  - Dropout regularization\")\n",
    "print(\"\\nExpected training time: 3-5 hours\")\n",
    "print(\"\\nMonitor GPU memory during training:\")\n",
    "print(\"  watch -n 1 nvidia-smi\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "history = trainer.fit(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    eval_dataset=eval_dataset,\n",
    "    num_epochs=35,           # More epochs for improved model\n",
    "    learning_rate=1e-3,      # Standard learning rate\n",
    "    weight_decay=1e-5,       # L2 regularization\n",
    "    patience=5,              # Early stopping patience\n",
    "    label_smoothing=0.0,     # No label smoothing for baseline\n",
    "    save_dir='../checkpoints'\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import plot_training_history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Plotting training history...\")\n",
    "plot_training_history(history)\n",
    "plt.show()\n",
    "\n",
    "# Save history\n",
    "with open('../results/improved_baseline_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "print(\"\\n‚úì History saved to results/improved_baseline_history.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import evaluate_model\n",
    "\n",
    "print(\"Running final evaluation...\\n\")\n",
    "\n",
    "results, captions, refs = evaluate_model(\n",
    "    trainer.model,\n",
    "    eval_dataset,\n",
    "    vocab,\n",
    "    device=device,\n",
    "    num_samples=100\n",
    ")\n",
    "\n",
    "# Save results\n",
    "serializable_results = make_json_serializable(results)\n",
    "with open('../results/improved_baseline_results.json', 'w') as f:\n",
    "    json.dump(serializable_results, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úì Results saved to results/improved_baseline_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Show Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import get_sample_predictions, print_sample_predictions\n",
    "\n",
    "print(\"Generating sample predictions...\\n\")\n",
    "\n",
    "samples = get_sample_predictions(\n",
    "    trainer.model,\n",
    "    eval_dataset,\n",
    "    vocab,\n",
    "    device=device,\n",
    "    num_samples=10\n",
    ")\n",
    "\n",
    "print_sample_predictions(samples, num_to_print=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Compare with Baseline (Optional)\n",
    "\n",
    "If you trained the baseline model, let's compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import pandas as pd\n",
    "\n",
    "# Try to load baseline results for comparison\n",
    "baseline_path = '../results/baseline_results.json'\n",
    "\n",
    "if osp.exists(baseline_path):\n",
    "    print(\"Comparing with baseline model...\\n\")\n",
    "    \n",
    "    with open(baseline_path, 'r') as f:\n",
    "        baseline_results = json.load(f)\n",
    "    \n",
    "    # Create comparison table\n",
    "    comparison = pd.DataFrame({\n",
    "        'Baseline': baseline_results,\n",
    "        'Improved Baseline': serializable_results\n",
    "    }).T\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"MODEL COMPARISON\")\n",
    "    print(\"=\"*80)\n",
    "    print(comparison.to_string())\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Calculate improvements\n",
    "    print(\"\\nIMPROVEMENTS:\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Repetition (lower is better)\n",
    "    rep_improvement = ((baseline_results['avg_repetition_rate'] - serializable_results['avg_repetition_rate']) \n",
    "                      / baseline_results['avg_repetition_rate'] * 100)\n",
    "    print(f\"Repetition rate: {rep_improvement:+.1f}% (lower is better)\")\n",
    "    \n",
    "    # Diversity (higher is better)\n",
    "    div_improvement = ((serializable_results['vocabulary_diversity'] - baseline_results['vocabulary_diversity']) \n",
    "                      / baseline_results['vocabulary_diversity'] * 100)\n",
    "    print(f\"Vocabulary diversity: {div_improvement:+.1f}% (higher is better)\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"Baseline results not found. Skipping comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nModel: Improved Baseline\")\n",
    "print(f\"  - Embedding dim: 256\")\n",
    "print(f\"  - Hidden dim: 512\")\n",
    "print(f\"  - LSTM layers: 2\")\n",
    "print(f\"  - Parameters: {total_params:,}\")\n",
    "\n",
    "print(f\"\\nArchitecture improvements:\")\n",
    "print(f\"  ‚úì Deeper CNN encoder (4 layers)\")\n",
    "print(f\"  ‚úì Bidirectional LSTM for temporal modeling\")\n",
    "print(f\"  ‚úì Audio context concatenation\")\n",
    "print(f\"  ‚úì Dropout regularization (0.3)\")\n",
    "print(f\"  ‚úì Average pooling (preserves temporal info)\")\n",
    "\n",
    "print(f\"\\nBest validation loss: {min(history['val_loss']):.4f}\")\n",
    "\n",
    "print(f\"\\nEvaluation metrics:\")\n",
    "print(f\"  - Repetition rate: {results['avg_repetition_rate']:.4f}\")\n",
    "print(f\"  - Vocabulary diversity: {results['vocabulary_diversity']:.4f}\")\n",
    "print(f\"  - Mean caption length: {results['mean_caption_length']:.2f} words\")\n",
    "print(f\"  - Unique words used: {results['unique_words_used']}\")\n",
    "\n",
    "print(f\"\\nFiles saved:\")\n",
    "print(f\"  ‚úì ../checkpoints/best_improved_baseline.pth\")\n",
    "print(f\"  ‚úì ../results/improved_baseline_history.json\")\n",
    "print(f\"  ‚úì ../results/improved_baseline_results.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Next steps:\")\n",
    "print(\"  - Train attention model: 03_train_attention_memory_efficient.ipynb\")\n",
    "print(\"  - Train transformer: 04_train_transformer_memory_efficient.ipynb\")\n",
    "print(\"  - Compare all models: 05_evaluate_all_memory_efficient.ipynb\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Improvements Over Baseline\n",
    "\n",
    "The improved baseline should show:\n",
    "\n",
    "### Better Audio Understanding\n",
    "- **Deeper CNN**: Extracts more complex audio features\n",
    "- **Bidirectional LSTM**: Captures temporal context from both directions\n",
    "- **Average pooling**: Preserves more temporal information than max pooling\n",
    "\n",
    "### Better Caption Generation\n",
    "- **Audio context concatenation**: Decoder has direct access to audio encoding at each step\n",
    "- **Dropout**: Reduces overfitting, improves generalization\n",
    "- **Larger capacity**: More parameters to learn complex patterns\n",
    "\n",
    "### Typical Improvements\n",
    "- **15-25%** reduction in repetition rate\n",
    "- **10-20%** increase in vocabulary diversity\n",
    "- **5-15%** increase in mean caption length\n",
    "- **Better semantic accuracy** (validated with reference metrics)\n",
    "\n",
    "### Trade-offs\n",
    "- ‚ö° **Slightly slower**: ~1.5x training time vs baseline\n",
    "- üíæ **More memory**: ~2-3x parameters vs baseline\n",
    "- üéØ **Better quality**: Worth the computational cost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
