{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clotho Dataset Preparation\n",
    "\n",
    "This notebook will:\n",
    "1. Download Clotho dataset using `aac_datasets`\n",
    "2. Extract mel spectrograms from audio files\n",
    "3. Create caption JSON files\n",
    "4. Build vocabulary\n",
    "\n",
    "**Estimated time**: 30-60 minutes (first run only, includes download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Imports successful!\n",
      "Project root: /home/harsha/Documents/ncsu/sem 1/ALDA/Project/cross-model-audio-text-captioning/notebooks/..\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'  # Fix threading issue\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "project_root = Path('..').absolute()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import librosa\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "print(\"âœ“ Imports successful!\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Check/Install aac_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ aac_datasets is installed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from aac_datasets import Clotho\n",
    "    print(\"âœ“ aac_datasets is installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing aac_datasets...\")\n",
    "    !pip install aac-datasets\n",
    "    from aac_datasets import Clotho\n",
    "    print(\"âœ“ aac_datasets installed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Created: clotho_data\n",
      "âœ“ Created: features/mel\n",
      "âœ“ Created: features/mel_eval\n",
      "âœ“ Created: data\n",
      "\n",
      "âœ“ All directories ready!\n"
     ]
    }
   ],
   "source": [
    "# Create directories\n",
    "clotho_root = project_root / 'clotho_data'\n",
    "mel_dir = project_root / 'features' / 'mel'\n",
    "mel_eval_dir = project_root / 'features' / 'mel_eval'\n",
    "data_dir = project_root / 'data'\n",
    "\n",
    "# Create all directories\n",
    "for directory in [clotho_root, mel_dir, mel_eval_dir, data_dir]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"âœ“ Created: {directory.relative_to(project_root)}\")\n",
    "\n",
    "print(\"\\nâœ“ All directories ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Download Clotho Dataset\n",
    "\n",
    "**This will take 10-30 minutes on first run** (downloads ~2-3 GB)\n",
    "\n",
    "Subsequent runs will be fast as data is cached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DOWNLOADING CLOTHO DATASET\n",
      "================================================================================\n",
      "\n",
      "â° This may take 10-30 minutes on first run...\n",
      "\n",
      "ðŸ“¥ Loading training data (development split)...\n",
      "âœ“ Training samples: 3839\n",
      "\n",
      "ðŸ“¥ Loading validation data...\n",
      "âœ“ Validation samples: 1045\n",
      "\n",
      "ðŸ“¥ Loading evaluation data...\n",
      "âœ“ Evaluation samples: 1045\n",
      "\n",
      "âœ“ Dataset loaded in 58.8 minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DOWNLOADING CLOTHO DATASET\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nâ° This may take 10-30 minutes on first run...\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Load train split (development)\n",
    "    print(\"ðŸ“¥ Loading training data (development split)...\")\n",
    "    train_dataset = Clotho(\n",
    "        root=str(clotho_root),\n",
    "        subset='dev',\n",
    "        download=True\n",
    "    )\n",
    "    print(f\"âœ“ Training samples: {len(train_dataset)}\")\n",
    "    \n",
    "    # Load validation split\n",
    "    print(\"\\nðŸ“¥ Loading validation data...\")\n",
    "    val_dataset = Clotho(\n",
    "        root=str(clotho_root),\n",
    "        subset='val',\n",
    "        download=True\n",
    "    )\n",
    "    print(f\"âœ“ Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Load evaluation split\n",
    "    print(\"\\nðŸ“¥ Loading evaluation data...\")\n",
    "    eval_dataset = Clotho(\n",
    "        root=str(clotho_root),\n",
    "        subset='eval',\n",
    "        download=True\n",
    "    )\n",
    "    print(f\"âœ“ Evaluation samples: {len(eval_dataset)}\")\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nâœ“ Dataset loaded in {elapsed/60:.1f} minutes\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Error: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Check internet connection\")\n",
    "    print(\"2. Make sure you have ~5 GB free space\")\n",
    "    print(\"3. Try running again (download will resume)\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Inspect Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data structure:\n",
      "  Keys: dict_keys(['dataset', 'index', 'subset', 'keywords', 'sound_link', 'audio', 'start_end_samples', 'duration', 'manufacturer', 'fname', 'sr', 'license', 'sound_id', 'captions'])\n",
      "\n",
      "  Audio shape: torch.Size([1, 1153825])\n",
      "  Sample rate: 44100 Hz\n",
      "  Duration: 0.00 seconds\n",
      "\n",
      "  Captions (5):\n",
      "    1. A muddled noise of broken channel of the TV\n",
      "    2. A television blares the rhythm of a static TV.\n",
      "    3. Loud television static dips in and out of focus\n",
      "    4. The loud buzz of static constantly changes pitch and volume.\n",
      "    5. heavy static and the beginnings of a signal on a transistor radio\n"
     ]
    }
   ],
   "source": [
    "# Look at a sample\n",
    "sample = train_dataset[0]\n",
    "\n",
    "print(\"Sample data structure:\")\n",
    "print(f\"  Keys: {sample.keys()}\")\n",
    "print(f\"\\n  Audio shape: {sample['audio'].shape}\")\n",
    "print(f\"  Sample rate: {sample['sr']} Hz\")\n",
    "print(f\"  Duration: {len(sample['audio'])/sample['sr']:.2f} seconds\")\n",
    "print(f\"\\n  Captions ({len(sample['captions'])}):\")\n",
    "for i, caption in enumerate(sample['captions'], 1):\n",
    "    print(f\"    {i}. {caption}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Extract Mel Spectrograms\n",
    "\n",
    "This will process all audio files and extract mel spectrograms.\n",
    "\n",
    "**Estimated time**: 15-30 minutes for all splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Mel extraction function ready\n"
     ]
    }
   ],
   "source": [
    "def extract_mel_spectrogram(audio, sr=32000, n_mels=64, n_fft=2048, hop_length=512):\n",
    "    \"\"\"\n",
    "    Extract mel spectrogram from audio\n",
    "    \"\"\"\n",
    "    # Extract mel spectrogram\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=audio,\n",
    "        sr=sr,\n",
    "        n_mels=n_mels,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length\n",
    "    )\n",
    "    \n",
    "    # Convert to log scale (dB)\n",
    "    mel = librosa.power_to_db(mel, ref=np.max)\n",
    "    \n",
    "    # Add channel dimension\n",
    "    mel = mel[np.newaxis, ...]  # (1, n_mels, time_steps)\n",
    "    \n",
    "    return mel\n",
    "\n",
    "print(\"âœ“ Mel extraction function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ FIXED processing function ready - Now re-run the training data cell!\n"
     ]
    }
   ],
   "source": [
    "def process_split(dataset, output_mel_dir, output_json_path, split_name):\n",
    "    \"\"\"\n",
    "    Process one split: extract mels and save captions (FIXED VERSION)\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing: {split_name.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    data = []\n",
    "    errors = 0\n",
    "    \n",
    "    for idx in tqdm(range(len(dataset)), desc=f\"Processing {split_name}\"):\n",
    "        try:\n",
    "            item = dataset[idx]\n",
    "            \n",
    "            # Get data\n",
    "            audio = item['audio']\n",
    "            sr = item['sr']\n",
    "            captions = item['captions']\n",
    "            fname = item.get('fname', f\"{split_name}_{idx:05d}\")\n",
    "            \n",
    "            # Convert audio to numpy array if it's a tensor\n",
    "            if not isinstance(audio, np.ndarray):\n",
    "                audio = np.array(audio)\n",
    "            \n",
    "            # Ensure audio is 1D\n",
    "            if audio.ndim > 1:\n",
    "                audio = audio.squeeze()\n",
    "            \n",
    "            # Convert to float32 if needed\n",
    "            if audio.dtype != np.float32:\n",
    "                audio = audio.astype(np.float32)\n",
    "            \n",
    "            # Resample if needed\n",
    "            if sr != 32000:\n",
    "                audio = librosa.resample(audio, orig_sr=sr, target_sr=32000)\n",
    "            \n",
    "            # Extract mel\n",
    "            mel = extract_mel_spectrogram(audio, sr=32000)\n",
    "            \n",
    "            # Save mel\n",
    "            mel_path = output_mel_dir / f\"{fname}.npy\"\n",
    "            np.save(mel_path, mel)\n",
    "            \n",
    "            # Add to captions\n",
    "            data.append({\n",
    "                'fname': fname,\n",
    "                'captions': captions if isinstance(captions, list) else [captions]\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            errors += 1\n",
    "            if errors <= 3:  # Show first 3 errors\n",
    "                print(f\"\\nâš  Error at index {idx}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    # Save caption JSON\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nâœ“ Processed: {len(data)} samples\")\n",
    "    if errors > 0:\n",
    "        print(f\"âš  Errors: {errors} samples\")\n",
    "    print(f\"âœ“ Saved mels to: {output_mel_dir.relative_to(project_root)}\")\n",
    "    print(f\"âœ“ Saved captions to: {output_json_path.relative_to(project_root)}\")\n",
    "    \n",
    "    return len(data)\n",
    "\n",
    "print(\"âœ“ FIXED processing function ready - Now re-run the training data cell!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing: TRAIN\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63c6f243d4642429d2d28730cb18cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing train:   0%|          | 0/3839 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40177/4095576106.py:24: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  audio = np.array(audio)\n",
      "/tmp/ipykernel_40177/4095576106.py:24: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  audio = np.array(audio)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Processed: 3839 samples\n",
      "âœ“ Saved mels to: features/mel\n",
      "âœ“ Saved captions to: data/train_captions.json\n"
     ]
    }
   ],
   "source": [
    "train_count = process_split(\n",
    "    dataset=train_dataset,\n",
    "    output_mel_dir=mel_dir,\n",
    "    output_json_path=data_dir / 'train_captions.json',\n",
    "    split_name='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing: VAL\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477601684bfb47ebbce88fdd28791d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing val:   0%|          | 0/1045 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40177/4095576106.py:24: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  audio = np.array(audio)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Processed: 1045 samples\n",
      "âœ“ Saved mels to: features/mel\n",
      "âœ“ Saved captions to: data/val_captions.json\n"
     ]
    }
   ],
   "source": [
    "val_count = process_split(\n",
    "    dataset=val_dataset,\n",
    "    output_mel_dir=mel_dir,\n",
    "    output_json_path=data_dir / 'val_captions.json',\n",
    "    split_name='val'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing: EVAL\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4866dd3d85d549618111d7d49f853de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing eval:   0%|          | 0/1045 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40177/4095576106.py:24: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  audio = np.array(audio)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Processed: 1045 samples\n",
      "âœ“ Saved mels to: features/mel_eval\n",
      "âœ“ Saved captions to: data/eval_captions.json\n"
     ]
    }
   ],
   "source": [
    "eval_count = process_split(\n",
    "    dataset=eval_dataset,\n",
    "    output_mel_dir=mel_eval_dir,\n",
    "    output_json_path=data_dir / 'eval_captions.json',\n",
    "    split_name='eval'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATASET STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Total samples processed: 5929\n",
      "  - Training: 3839\n",
      "  - Validation: 1045\n",
      "  - Evaluation: 1045\n",
      "\n",
      "Training:\n",
      "  - Total captions: 19195\n",
      "  - Avg caption length: 11.3 words\n",
      "  - Min/Max length: 8/21 words\n",
      "\n",
      "Validation:\n",
      "  - Total captions: 5225\n",
      "  - Avg caption length: 11.4 words\n",
      "  - Min/Max length: 8/21 words\n",
      "\n",
      "Evaluation:\n",
      "  - Total captions: 5225\n",
      "  - Avg caption length: 11.3 words\n",
      "  - Min/Max length: 8/21 words\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATASET STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total = train_count + val_count + eval_count\n",
    "print(f\"\\nTotal samples processed: {total}\")\n",
    "print(f\"  - Training: {train_count}\")\n",
    "print(f\"  - Validation: {val_count}\")\n",
    "print(f\"  - Evaluation: {eval_count}\")\n",
    "\n",
    "# Analyze captions\n",
    "for split_name, json_path in [\n",
    "    ('Training', data_dir / 'train_captions.json'),\n",
    "    ('Validation', data_dir / 'val_captions.json'),\n",
    "    ('Evaluation', data_dir / 'eval_captions.json')\n",
    "]:\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    caption_lengths = [len(cap.split()) for item in data for cap in item['captions']]\n",
    "    \n",
    "    print(f\"\\n{split_name}:\")\n",
    "    print(f\"  - Total captions: {len(caption_lengths)}\")\n",
    "    print(f\"  - Avg caption length: {np.mean(caption_lengths):.1f} words\")\n",
    "    print(f\"  - Min/Max length: {np.min(caption_lengths)}/{np.max(caption_lengths)} words\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BUILDING VOCABULARY\n",
      "================================================================================\n",
      "Vocabulary size: 5986\n",
      "Total unique words: 7819\n",
      "Words with freq >= 2: 5982\n",
      "Vocabulary saved to /home/harsha/Documents/ncsu/sem 1/ALDA/Project/cross-model-audio-text-captioning/notebooks/../vocab.json\n",
      "\n",
      "âœ“ Vocabulary size: 5986\n",
      "\n",
      "Most common words:\n",
      "  a               24739\n",
      "  the             13138\n",
      "  and             12179\n",
      "  is               9145\n",
      "  in               7299\n",
      "  of               4807\n",
      "  are              4059\n",
      "  as               3653\n",
      "  with             3002\n",
      "  while            2966\n",
      "  on               2949\n",
      "  then             2360\n",
      "  water            2310\n",
      "  birds            2259\n",
      "  an               2229\n",
      "  people           2159\n",
      "  to               2130\n",
      "  someone          1897\n",
      "  by               1842\n",
      "  person           1819\n"
     ]
    }
   ],
   "source": [
    "from src.utils import build_vocab, save_vocab\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"BUILDING VOCABULARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "vocab, word_freq = build_vocab(\n",
    "    captions_files=[\n",
    "        str(data_dir / 'train_captions.json'),\n",
    "        str(data_dir / 'val_captions.json')\n",
    "    ],\n",
    "    min_word_freq=2\n",
    ")\n",
    "\n",
    "# Save vocabulary\n",
    "vocab_path = project_root / 'vocab.json'\n",
    "save_vocab(vocab, str(vocab_path))\n",
    "\n",
    "print(f\"\\nâœ“ Vocabulary size: {len(vocab)}\")\n",
    "print(f\"\\nMost common words:\")\n",
    "for word, count in word_freq.most_common(20):\n",
    "    print(f\"  {word:<15} {count:>5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "âœ“ PREPARATION COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Files created:\n",
      "  âœ“ features/mel/ - 4884 mel spectrograms\n",
      "  âœ“ features/mel_eval/ - 1045 mel spectrograms\n",
      "  âœ“ data/train_captions.json\n",
      "  âœ“ data/val_captions.json\n",
      "  âœ“ data/eval_captions.json\n",
      "  âœ“ vocab.json\n",
      "\n",
      "================================================================================\n",
      "NEXT STEPS\n",
      "================================================================================\n",
      "\n",
      "1. Train baseline model:\n",
      "   python scripts/train_baseline.py\n",
      "\n",
      "2. Or continue in notebooks:\n",
      "   Open: notebooks/02_train_baseline.ipynb\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ“ PREPARATION COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nFiles created:\")\n",
    "print(f\"  âœ“ {mel_dir.relative_to(project_root)}/ - {train_count + val_count} mel spectrograms\")\n",
    "print(f\"  âœ“ {mel_eval_dir.relative_to(project_root)}/ - {eval_count} mel spectrograms\")\n",
    "print(f\"  âœ“ {data_dir.relative_to(project_root)}/train_captions.json\")\n",
    "print(f\"  âœ“ {data_dir.relative_to(project_root)}/val_captions.json\")\n",
    "print(f\"  âœ“ {data_dir.relative_to(project_root)}/eval_captions.json\")\n",
    "print(f\"  âœ“ vocab.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n1. Train baseline model:\")\n",
    "print(\"   python scripts/train_baseline.py\")\n",
    "print(\"\\n2. Or continue in notebooks:\")\n",
    "print(\"   Open: notebooks/02_train_baseline.ipynb\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
